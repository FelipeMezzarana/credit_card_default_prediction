{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b8b5781",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8ba163",
   "metadata": {
    "hidden": true
   },
   "source": [
    "***Warning:*** This is the second script of this project. in the first one (\"eda_and_feature_engineering\"), we define the problem, explored the data, we did an initial treatment and created some features. I strongly recommend that you visit the first script before exploring this one, they are two parts of the same project, and were split just to avoid an extremely large script, improving the organization.\n",
    "\n",
    "**Method:**\n",
    "\n",
    "As mentioned, we have already pre-treated our data. However, the EDA revealed that we have ***unbalanced data***, we need to understand witch technique should be used to train our model. In order to build the best possible model, we also need to perform feature selection. \n",
    "\n",
    "All considered, we decided to opt for an iterative methodology, as described below:\n",
    "\n",
    "+ Define and prepare metrics to be easily applicable \n",
    "+ Develop a pipeline to build a model and create a baseline with the raw DataFrame\n",
    "+ Treat the imbalance data problem and choose the best technique\n",
    "+ Feature selection and engineering\n",
    "+ Model selection and hyperparameter tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ce83d1",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380e5272",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import math as mt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import imblearn\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faa2f14",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d216f8ac",
   "metadata": {},
   "source": [
    "**Defining metrics**\n",
    "\n",
    "Evaluating a classification model may not be the easiest task. In order to obtain a consistent result it will be necessary to use a set of metrics, we will adopt:\n",
    "\n",
    "+ recall -- Indicates the occurrence of false negative, e.g, predict indicated that default would NOT occur, but it did\n",
    "+ precision -- Indicates rate at which positive predictions are correct, e.g, predict indicated that default would occur, and it did\n",
    "    + Please note: in our case, **recall will have greater relevance**, because predicting a false negative will result in greater losses for the business than predicting a false positive\n",
    "+ F1 -- A function of Precision and Recall. Even though Recall is more important, precision is also relevant, because wrongly predicting that a default will happen, also results in business loses. So it is good to have a metric that represents a balance between Precision and Recall. \n",
    "+ ROC Curve -- Until now, our metrics are considering 3 of 4 values of the confusion matrix, we are not looking at true negatives! We could use Accuracy or Specificity to include true negative in our analyses, but we expected that the majority of data will be true negative, so those metrics may be misleading. Instead, we will use the ROC curve, that shows the relation between  True Positive Rate and True Negative Rate. \n",
    "+ AUC -- Its the area under the ROC curve, it is a simple way to measure the ROC Curve.\n",
    "\n",
    "\n",
    "***To make our life easier, we will define a class that calculates and displays all the desired metrics***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbeb878e",
   "metadata": {},
   "source": [
    "**Important:**\n",
    "\n",
    "To make our notebook easier to read and make our work more scalable, we separate our class and functions that calculates metrics and show relevant charts in a .py file, and here, we will just import it. ***Please, check the file classification.py found in this same repository for better understanding***\n",
    "\n",
    "Inside classification.py we have:\n",
    "+ Definition of Metrics class that receive two lists (list of predict default and list of actual default) Ex: ***my_metrics = classification.Metrics(y_true,y_pred)***\n",
    "    + Define the desired metrics as attributes and print it. Ex: ***my_metrics.show_metrics()***\n",
    "    + Plot metrics chart (may be: Confusion Matrix, ROC Curve or both) and display then. Ex: ***my_metrics.show_charts()***\n",
    "    + print metrics and display all charts. Ex: ***my_metrics.show_all()***\n",
    "    \n",
    "We also have a function to calculate mean metrics, generate overlapped charts, and other useful infos for multiple Metrics objects. Please note that To prevent overfitting, we will use Stratified K-Folds cross-validator to evaluate our models. Therefore, it will be interesting to have a function that can receive multiple metrics objects (one for each fold). \n",
    "+ Ex of function usage: ***classification.show_mean_metrics([my_metrics,my_metrics2,my_metrics3])***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c65fc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing classification.py\n",
    "\n",
    "import classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1f1268",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f765432",
   "metadata": {},
   "source": [
    "## Building pipeline functions and a Baseline "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3707842d",
   "metadata": {},
   "source": [
    "Now that we we define and prepare our metrics, its time to develop the model! Following the logic defined in our method, we are going to create some functions to facilitate the definition of differents pipelines.\n",
    "\n",
    "***The pipeline will:***\n",
    "+ Receive the features as keywords (X,y)\n",
    "+ Use StratifiedKFold cross validation technique to divide the data in 10 (or n) folds\n",
    "    + We will use StratifiedKFold instead of normal K-fold  to preserve the percentage of samples for the target category in each fold.\n",
    "+ Pre processing the training data ***(isolating test data to avoid overfitting)***. ps: Step not included in in the definition of baseline \n",
    "+ Build a Classifier model for each fold and make predictions with the validation data. \n",
    "    + We will start using a Random Forest model, which usually performs well in this type of problem. At the end of the work, we will evaluate other models\n",
    "+ Calculate metrics for each fold using our pre defined Metrics class, and display a summary of the results.\n",
    "\n",
    "***This way, we can obtain a baseline with the original data, without any type of treatment, and as we process the data (treating imbalance and doing feature engineering) it will be easier to test our hypotheses and evaluate our improvement!***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a70641",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_kfolds(X,y,n = 10):\n",
    "    \n",
    "    \"\"\"Return 4 lists containing training and validation data, divided in n Stratified KFolds\n",
    "\n",
    "    Keyword arguments:\n",
    "    X -- Independent features - excluding target variable \n",
    "    y -- Dependent variable - target\n",
    "    n -- Number of folds (default = 10)\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the StratifiedKFold object\n",
    "    skf = StratifiedKFold(n_splits=n, shuffle=True)\n",
    "\n",
    "    X_train_list,X_test_list,y_train_list,y_test_list = [[] for i in range(4)]\n",
    "    # Split features in folds\n",
    "    for train_index, test_index in skf.split(X,y):\n",
    "\n",
    "        X_train_list.append(X.loc[train_index])\n",
    "        X_test_list.append(X.loc[test_index])\n",
    "        y_train_list.append(y.loc[train_index])\n",
    "        y_test_list.append( y.loc[test_index])\n",
    "\n",
    "    return X_train_list, X_test_list, y_train_list,y_test_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89ee2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_randon_forest(X_train_list, X_test_list, y_train_list,y_test_list):\n",
    "    \n",
    "    \"\"\"Show all pre-defined metrics for a Random Forest model, trained and tested with n-folds defined in args \n",
    "    * Train a Random Forest Classifier model for each fold \n",
    "    * For each model, predict y with test data \n",
    "    * For each model, create a metrics object with actual and predicted y, and use it to print \"mean metrics\"\n",
    "\n",
    "    Keyword arguments:\n",
    "    x_train_list -- list with n folds for training the model \n",
    "    x_test_list -- list with n folds for testing the model \n",
    "    y_train_list -- list with n folds containing training dependent variable (target)\n",
    "    y_test_list -- list with n folds containing test dependent variable (target)\n",
    "    \"\"\"\n",
    "\n",
    "    metrics_list =[]\n",
    "    # Split features in folds\n",
    "    for X_train, X_test, y_train,y_test in zip(X_train_list, X_test_list, y_train_list,y_test_list):\n",
    "\n",
    "        # Creating a Random Forest Classifier with standard hyperparameters. \n",
    "        # We will do hyperparameter tuning in the appropriate time\n",
    "        rfc = RandomForestClassifier(random_state=42)\n",
    "        rfc.fit(X_train, y_train)\n",
    "        \n",
    "        rfc_predict = rfc.predict(X_test)\n",
    "        \n",
    "        prov_metrics = classification.Metrics(y_test,rfc_predict)\n",
    "        metrics_list.append(prov_metrics)\n",
    "        \n",
    "    # Show metrics\n",
    "    classification.show_mean_metrics(metrics_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9944dae3",
   "metadata": {},
   "source": [
    "***First of all, lets load our pre-treated DataFrame and establish a baseline!***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27b68ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading df\n",
    "default_credit_card = pd.read_csv(r'data\\default_of_credit_card_clients_treated.csv')\n",
    "default_credit_card.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b476ab",
   "metadata": {},
   "source": [
    "For the Baseline, we will ***keep only continuous and originals features*** (before feature engineering)\n",
    "\n",
    "We will also ***retrieve 20% of data*** using train_test_split, for final evaluation. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee79b0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing categorical features and target \n",
    "X  = default_credit_card.loc[:,['limit_bal'] + default_credit_card.columns[5:23].tolist()]\n",
    "# Geting target\n",
    "y = default_credit_card.default_payment_next_month\n",
    "\n",
    "# Spliting data into training and validation k-folds and appending folds to lists\n",
    "X_train_list, X_test_list, y_train_list, y_test_list = divide_kfolds(X, y)\n",
    "\n",
    "#Evaluating Baseline with raw data (Randon Forest classifier)\n",
    "evaluate_randon_forest(X_train_list, X_test_list, y_train_list,y_test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17aaec9d",
   "metadata": {},
   "source": [
    "***As expected, we had really bad results!*** After all, we simply created a model with the raw data, without any treatment. \n",
    "\n",
    "let's start dealing with the imbalance data problem and see how much we can improve the results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910ee5dc",
   "metadata": {},
   "source": [
    "## Treating Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d69195f",
   "metadata": {},
   "source": [
    "To combat imbalanced we will try three different techniques:\n",
    "\n",
    "+ Undersampling (resampling data)\n",
    "+ Oversampling (resampling data)\n",
    "+ SMOTE (Generate Synthetic Samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf0d113",
   "metadata": {},
   "source": [
    "### Undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494e9859",
   "metadata": {},
   "source": [
    "Undersampling consists in deleting data from the majority class until we have balanced data, i.e, an equal number of examples for each class.\n",
    "\n",
    "A potential problem with this technique is that if the imbalance is severe, a lot of data will be deleted, which can make the differences between classes more difficult to learn.\n",
    "\n",
    "To implement this technique we will use ***RandomUnderSampler***.  From [documentation](https://imbalanced-learn.org/stable/under_sampling.html) we found the definition: \"RandomUnderSampler is a fast and easy way to balance the data by randomly selecting a subset of data for the targeted classes\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd3e963",
   "metadata": {},
   "source": [
    "let's develop a function to apply Undersampling in n k-folds, so we can include this processing in our model pipeline, ***applying only in training data***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a339545a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def undersampling_kfolds(X_train_list,y_train_list):\n",
    "    \n",
    "    \"\"\"return n training data folds with Undersampling technique applied\n",
    "    * It is very important to apply this processing only in the training that\n",
    "    * this way, our validation data will remain faithful to a real production situation,avoiding overfitting\n",
    "\n",
    "    Keyword arguments:\n",
    "    X_train_list -- list with n folds for training the model \n",
    "    y_train_list -- list with n folds containing training dependent variable (target)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define undersample strategy\n",
    "    # “majority” will undersample the majority class determined by the class with the largest number of examples.  \n",
    "    undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "\n",
    "    # Process training data and append resampled folds to lists\n",
    "    X_under_resampled_list, y_under_resampled_list = [[] for i in range(2)] \n",
    "    for X_train, y_train in zip(X_train_list,y_train_list):\n",
    "        X_under_resampled, y_under_resampled = undersample.fit_resample(X_train, y_train)\n",
    "        X_under_resampled_list.append(X_under_resampled)\n",
    "        y_under_resampled_list.append(y_under_resampled)\n",
    "        \n",
    "    return X_under_resampled_list,y_under_resampled_list\n",
    "                                              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4677e1",
   "metadata": {},
   "source": [
    "***Evaluation Pipeline:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373e0a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting data into training and validation k-folds and appending folds to lists\n",
    "X_train_list, X_test_list, y_train_list, y_test_list = divide_kfolds(X, y)\n",
    "\n",
    "# Appling Undersampling ONLY IN TRAING DATA\n",
    "X_under_resampled_train_list,y_under_resampled_train_list = undersampling_kfolds(X_train_list,y_train_list)\n",
    "\n",
    "#Evaluating Model with Undersampling treatment (Randon Forest classifier)\n",
    "evaluate_randon_forest(X_under_resampled_train_list, X_test_list, y_under_resampled_train_list,y_test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40db63f",
   "metadata": {},
   "source": [
    "***For sure we lost a good amount of data, but now we have balanced data. Because of that, we achieved a great improvement over our baseline!***\n",
    "\n",
    "Although we noticed a small improvement in the ROC Curve (mean AUC went from 0.65 to 0.7) ***the biggest improvement can be seen in the Recall, which went from 0.37 to 0.64!*** This means that we are having a lot less false negative. \n",
    "\n",
    "However, the loss of data seems to have had a negative impact on the model, as the improvement in other metrics was very subtle. Let's try other techniques that can alleviate this problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3384fa0f",
   "metadata": {},
   "source": [
    "### Oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b271efe",
   "metadata": {},
   "source": [
    "Oversampling has a similar principle to undersampling, but instead of deleting data, we will duplicate examples from the minority class. \n",
    "\n",
    "A potential problem with this technique is that it may increase the likelihood of occurring overfitting, since it makes exact copies of the minority class examples.\n",
    "  \n",
    "To implement this technique we will use RandomOverSampler class, to randomly duplicate samples of minority class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c429035",
   "metadata": {},
   "source": [
    "let's develop a function to apply Oversampling in n k-folds, so we can include this processing in our model pipeline, ***applying only in training data***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ccc449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversampling_kfolds(X_train_list,y_train_list):\n",
    "    \n",
    "    \"\"\"return n training data folds with oversampling technique applied\n",
    "    * It is very important to apply this processing only in the training that\n",
    "    * this way, our validation data will not be contaminated,avoiding overfitting\n",
    "\n",
    "    Keyword arguments:\n",
    "    X_train_list -- list with n folds for training the model \n",
    "    y_train_list -- list with n folds containing training dependent variable (target)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define oversampling strategy\n",
    "    # “minority” will automatically balance the minority class with majority class\n",
    "    oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "\n",
    "    # Process training data and append resampled folds to lists\n",
    "    X_over_resampled_list, y_over_resampled_list = [[] for i in range(2)] \n",
    "    for X_train, y_train in zip(X_train_list,y_train_list):\n",
    "        X_over_resampled, y_over_resampled = oversample.fit_resample(X_train, y_train)\n",
    "        X_over_resampled_list.append(X_over_resampled)\n",
    "        y_over_resampled_list.append(y_over_resampled)\n",
    "        \n",
    "    return X_over_resampled_list,y_over_resampled_list\n",
    "                                              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c80380e",
   "metadata": {},
   "source": [
    "***Evaluation Pipeline:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ed497e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting data into training and validation k-folds and appending folds to lists\n",
    "X_train_list, X_test_list, y_train_list, y_test_list = divide_kfolds(X, y)\n",
    "\n",
    "# Appling Oversampling ONLY IN TRAING DATA\n",
    "X_over_resampled_list,y_over_resampled_list = oversampling_kfolds(X_train_list,y_train_list)\n",
    "\n",
    "#Evaluating Model with Oversampling treatment (Randon Forest classifier)\n",
    "evaluate_randon_forest(X_over_resampled_list, X_test_list, y_over_resampled_list,y_test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01880b1a",
   "metadata": {},
   "source": [
    "***We solved the imbalance problem, but we have a lot of repeated data***\n",
    "\n",
    "We were still able to improve our baseline, but not as much as using undersampling.\n",
    "\n",
    "In our case, it is clear thet **undersampling performed better them oversampling** \n",
    "\n",
    "Lets try the SMOTE resampling technique to see if we can improve results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1ce8ac",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c048b9a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f9c99c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b062ea0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263e70af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
